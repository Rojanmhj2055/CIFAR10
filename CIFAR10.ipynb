{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFAR10.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1FJUP-VFMoSL2eFy265T7z7SZN9Fx-k0Q",
      "authorship_tag": "ABX9TyNS9lBAzqQYgiZ7dEUGEcD5",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rojanmhj2055/CIFAR10/blob/master/CIFAR10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UExC1FojWVe4"
      },
      "source": [
        "%load_ext tensorboard\r\n",
        "!rm -rf ./logs/"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upSDYOW68SXK"
      },
      "source": [
        "#The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, \r\n",
        "#with 6000 images per class. There are 50000 training images and 10000 test images.\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "from tensorflow import keras\r\n",
        "import pandas\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import tensorflow_datasets as tfds\r\n",
        "from keras.datasets import cifar10\r\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCfOvqYkI2bI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6552b343-eb6c-4d38-8bcd-651430f4706c"
      },
      "source": [
        " (x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOthGn9DLpVd"
      },
      "source": [
        "import numpy as np\r\n",
        "\r\n",
        "label = [\"airplane\",\"automobile\",\"bird\",\"cat\",\"deer\",\"dog\",\"frog\",\"horse\",\"ship\",\"truck\"]\r\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKqOt8X87GJN"
      },
      "source": [
        "\r\n",
        "y_train = np_utils.to_categorical(y_train,len(label))\r\n",
        "y_test = np_utils.to_categorical(y_test,len(label))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJhWovbKe7EA",
        "outputId": "ba9ec8d4-87c8-4c68-82e5-c66a5abbff21"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGQHleY3pnRt"
      },
      "source": [
        "mean = np.mean(x_train,axis=(0,1,2,3))\r\n",
        "std = np.std(x_train,axis=(0,1,2,3))\r\n",
        "x_train = (x_train-mean)/(std+1e-7)\r\n",
        "x_test = (x_test-mean)/(std+1e-7)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIRJHXCZerAw"
      },
      "source": [
        "from keras.callbacks import LearningRateScheduler\r\n",
        "n_labels = 10\r\n",
        "def lr_schedule(epoch):\r\n",
        "  lrate = 0.001\r\n",
        "  if epoch>75:\r\n",
        "    lr=0.0005\r\n",
        "  elif epoch > 150:\r\n",
        "    lrate = 0.0003\r\n",
        "  return lrate   "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkJqq49hcSJw"
      },
      "source": [
        "def plot_model_history(model_history):\r\n",
        "    fig, axs = plt.subplots(1,2,figsize=(15,5))\r\n",
        "    # summarize history for accuracy\r\n",
        "    axs[0].plot(range(1,len(model_history.history['accuracy'])+1),model_history.history['accuracy']) \r\n",
        "    axs[0].plot(range(1,len(model_history.history['val_accuracy'])+1),model_history.history['val_accuracy'])\r\n",
        "    axs[0].set_title('Model Accuracy')\r\n",
        "    axs[0].set_ylabel('Accuracy')\r\n",
        "    axs[0].set_xlabel('Epoch')\r\n",
        "    axs[0].set_xticks(np.arange(1,len(model_history.history['accuracy'])+1),len(model_history.history['accuracy'])/10)\r\n",
        "    axs[0].legend(['train', 'val'], loc='best')\r\n",
        "    # summarize history for loss\r\n",
        "    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\r\n",
        "    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\r\n",
        "    axs[1].set_title('Model Loss')\r\n",
        "    axs[1].set_ylabel('Loss')\r\n",
        "    axs[1].set_xlabel('Epoch')\r\n",
        "    axs[1].set_xticks(np.arange(1,len(model_history.history['loss'])+1),len(model_history.history['loss'])/10)\r\n",
        "    axs[1].legend(['train', 'val'], loc='best')\r\n",
        "    plt.show()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WG7ZA9y4cueR"
      },
      "source": [
        "def get_model():\r\n",
        "  my_new_model =tf.keras.models.Sequential()\r\n",
        "\r\n",
        "  my_new_model.add(keras.layers.Conv2D(64,(3,3),padding='same',activation='elu',input_shape=(32,32,3),kernel_regularizer=keras.regularizers.L2(0.0001)))\r\n",
        "  my_new_model.add(keras.layers.Conv2D(64,(3,3),padding='same',activation='elu',input_shape=(32,32,3),kernel_regularizer=keras.regularizers.L2(0.0001)))\r\n",
        "  my_new_model.add(keras.layers.BatchNormalization())\r\n",
        "  my_new_model.add(keras.layers.MaxPool2D((2,2)))\r\n",
        "  my_new_model.add(keras.layers.Dropout(0.3))\r\n",
        "\r\n",
        "  my_new_model.add(keras.layers.Conv2D(128,(3,3),padding='same',activation=\"elu\",kernel_regularizer=keras.regularizers.L2(0.0001)))\r\n",
        "  my_new_model.add(keras.layers.Conv2D(128,(3,3),padding='same',activation=\"elu\",kernel_regularizer=keras.regularizers.L2(0.0001)))\r\n",
        "  my_new_model.add(keras.layers.BatchNormalization())\r\n",
        "  my_new_model.add(keras.layers.MaxPool2D((2,2)))\r\n",
        "\r\n",
        "  my_new_model.add(keras.layers.Conv2D(256,(3,3),padding='same',activation=\"elu\",kernel_regularizer=keras.regularizers.L2(0.0001)))\r\n",
        "  my_new_model.add(keras.layers.Conv2D(256,(3,3),padding='same',activation=\"elu\",kernel_regularizer=keras.regularizers.L2(0.0001)))\r\n",
        "  my_new_model.add(keras.layers.BatchNormalization())\r\n",
        "  my_new_model.add(keras.layers.MaxPool2D(2,2))\r\n",
        "  my_new_model.add(keras.layers.Dropout(rate=0.25))\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "  my_new_model.add(keras.layers.Conv2D(512,(3,3),padding='same',activation='elu',kernel_regularizer=keras.regularizers.l2(0.0001)))\r\n",
        "  my_new_model.add(keras.layers.BatchNormalization())\r\n",
        "  my_new_model.add(keras.layers.Conv2D(512,(3,3),padding='same',activation='elu',kernel_regularizer=keras.regularizers.l2(0.0001)))\r\n",
        "  my_new_model.add(keras.layers.BatchNormalization())\r\n",
        "  my_new_model.add(keras.layers.MaxPool2D((2,2)))\r\n",
        "  my_new_model.add(keras.layers.Dropout(0.5))\r\n",
        "  my_new_model.add(keras.layers.Flatten())\r\n",
        "\r\n",
        "  my_new_model.add(keras.layers.Dense(512,activation=\"elu\",kernel_regularizer= keras.regularizers.l2(0.0001)))\r\n",
        "  my_new_model.add(keras.layers.BatchNormalization())\r\n",
        "  my_new_model.add(keras.layers.Dropout(0.5))\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "  my_new_model.add(keras.layers.Dense(n_labels,activation=\"softmax\"))\r\n",
        "  \r\n",
        "  return my_new_model"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvvCaVnEfVpT",
        "outputId": "c236ee27-8dbf-4515-d605-b12faaac506d"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfYFmlPGyMCg"
      },
      "source": [
        "model  = get_model()\r\n",
        "\r\n",
        "optimizer = keras.optimizers.Adamax(lr=0.001,decay=1e-6)\r\n",
        "schedular = keras.callbacks.LearningRateScheduler(lr_schedule)\r\n",
        "# earlyStopping = keras.callbacks.EarlyStopping(monitor='accuracy',min_delta=0.5,patience=60,mode=\"max\")\r\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(\"/logs/mymodel\",histogram_freq=1)\r\n",
        "batch_size = 128\r\n",
        "epoch = 200"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWtukgoxSttf",
        "outputId": "37d4e236-b3b6-4a64-80fd-339797e9d519"
      },
      "source": [
        "#data agumentation \r\n",
        "import time\r\n",
        "from keras.preprocessing.image import ImageDataGenerator\r\n",
        "\r\n",
        "datagen = ImageDataGenerator(\r\n",
        "    width_shift_range=0.1,\r\n",
        "    height_shift_range=0.1,\r\n",
        "    horizontal_flip = True,\r\n",
        "    rotation_range = 90,\r\n",
        "  \r\n",
        ")\r\n",
        "\r\n",
        "datagen.fit(x_train)\r\n",
        "\r\n",
        "model.compile(optimizer=optimizer,loss=tf.keras.losses.CategoricalCrossentropy(),metrics=['accuracy'])\r\n",
        "start = time.time()\r\n",
        "history = model.fit(datagen.flow(x_train,y_train,batch_size=batch_size),steps_per_epoch=x_train.shape[0]//batch_size,epochs=epoch,\r\n",
        "                           validation_data=(x_test,y_test), verbose=1,callbacks=[schedular,tensorboard_callback])\r\n",
        "end=time.time()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "390/390 [==============================] - 39s 78ms/step - loss: 2.7626 - accuracy: 0.2610 - val_loss: 2.5870 - val_accuracy: 0.3262\n",
            "Epoch 2/200\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 2.0307 - accuracy: 0.3961 - val_loss: 2.1013 - val_accuracy: 0.4368\n",
            "Epoch 3/200\n",
            "390/390 [==============================] - 29s 73ms/step - loss: 1.8126 - accuracy: 0.4561 - val_loss: 2.9418 - val_accuracy: 0.4646\n",
            "Epoch 4/200\n",
            "390/390 [==============================] - 28s 73ms/step - loss: 1.6370 - accuracy: 0.5199 - val_loss: 1.6348 - val_accuracy: 0.5495\n",
            "Epoch 5/200\n",
            "390/390 [==============================] - 28s 73ms/step - loss: 1.5282 - accuracy: 0.5565 - val_loss: 2.0787 - val_accuracy: 0.5269\n",
            "Epoch 6/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 1.4289 - accuracy: 0.5963 - val_loss: 1.2672 - val_accuracy: 0.6512\n",
            "Epoch 7/200\n",
            "390/390 [==============================] - 28s 73ms/step - loss: 1.3305 - accuracy: 0.6268 - val_loss: 1.2278 - val_accuracy: 0.6609\n",
            "Epoch 8/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 1.2815 - accuracy: 0.6442 - val_loss: 1.3014 - val_accuracy: 0.6479\n",
            "Epoch 9/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 1.2375 - accuracy: 0.6616 - val_loss: 1.2988 - val_accuracy: 0.6547\n",
            "Epoch 10/200\n",
            "390/390 [==============================] - 28s 73ms/step - loss: 1.1789 - accuracy: 0.6822 - val_loss: 1.2607 - val_accuracy: 0.6748\n",
            "Epoch 11/200\n",
            "390/390 [==============================] - 28s 71ms/step - loss: 1.1395 - accuracy: 0.6961 - val_loss: 1.2077 - val_accuracy: 0.6878\n",
            "Epoch 12/200\n",
            "390/390 [==============================] - 28s 71ms/step - loss: 1.1266 - accuracy: 0.7010 - val_loss: 1.1581 - val_accuracy: 0.7046\n",
            "Epoch 13/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 1.0844 - accuracy: 0.7155 - val_loss: 1.1749 - val_accuracy: 0.6954\n",
            "Epoch 14/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 1.0552 - accuracy: 0.7248 - val_loss: 1.1343 - val_accuracy: 0.7001\n",
            "Epoch 15/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 1.0207 - accuracy: 0.7382 - val_loss: 1.1053 - val_accuracy: 0.7121\n",
            "Epoch 16/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.9882 - accuracy: 0.7454 - val_loss: 0.9476 - val_accuracy: 0.7625\n",
            "Epoch 17/200\n",
            "390/390 [==============================] - 28s 71ms/step - loss: 0.9779 - accuracy: 0.7488 - val_loss: 1.0674 - val_accuracy: 0.7340\n",
            "Epoch 18/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.9524 - accuracy: 0.7589 - val_loss: 1.0013 - val_accuracy: 0.7521\n",
            "Epoch 19/200\n",
            "390/390 [==============================] - 28s 71ms/step - loss: 0.9360 - accuracy: 0.7633 - val_loss: 0.9453 - val_accuracy: 0.7702\n",
            "Epoch 20/200\n",
            "390/390 [==============================] - 28s 71ms/step - loss: 0.9335 - accuracy: 0.7611 - val_loss: 1.0132 - val_accuracy: 0.7532\n",
            "Epoch 21/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.9012 - accuracy: 0.7756 - val_loss: 0.9250 - val_accuracy: 0.7702\n",
            "Epoch 22/200\n",
            "390/390 [==============================] - 28s 71ms/step - loss: 0.8829 - accuracy: 0.7846 - val_loss: 0.8714 - val_accuracy: 0.7880\n",
            "Epoch 23/200\n",
            "390/390 [==============================] - 28s 71ms/step - loss: 0.8793 - accuracy: 0.7813 - val_loss: 0.9738 - val_accuracy: 0.7641\n",
            "Epoch 24/200\n",
            "390/390 [==============================] - 28s 71ms/step - loss: 0.8643 - accuracy: 0.7878 - val_loss: 0.8946 - val_accuracy: 0.7851\n",
            "Epoch 25/200\n",
            "390/390 [==============================] - 28s 71ms/step - loss: 0.8605 - accuracy: 0.7883 - val_loss: 0.8808 - val_accuracy: 0.7929\n",
            "Epoch 26/200\n",
            "390/390 [==============================] - 28s 71ms/step - loss: 0.8349 - accuracy: 0.7982 - val_loss: 0.8768 - val_accuracy: 0.7953\n",
            "Epoch 27/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.8346 - accuracy: 0.7981 - val_loss: 0.9692 - val_accuracy: 0.7707\n",
            "Epoch 28/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.8164 - accuracy: 0.8056 - val_loss: 0.7934 - val_accuracy: 0.8211\n",
            "Epoch 29/200\n",
            "390/390 [==============================] - 28s 73ms/step - loss: 0.8081 - accuracy: 0.8071 - val_loss: 0.8282 - val_accuracy: 0.8037\n",
            "Epoch 30/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.7962 - accuracy: 0.8142 - val_loss: 0.8397 - val_accuracy: 0.8046\n",
            "Epoch 31/200\n",
            "390/390 [==============================] - 28s 71ms/step - loss: 0.8004 - accuracy: 0.8121 - val_loss: 0.8537 - val_accuracy: 0.7987\n",
            "Epoch 32/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.7847 - accuracy: 0.8170 - val_loss: 0.9603 - val_accuracy: 0.7739\n",
            "Epoch 33/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.7753 - accuracy: 0.8188 - val_loss: 0.8797 - val_accuracy: 0.7957\n",
            "Epoch 34/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.7688 - accuracy: 0.8218 - val_loss: 0.8161 - val_accuracy: 0.8110\n",
            "Epoch 35/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.7723 - accuracy: 0.8230 - val_loss: 0.8173 - val_accuracy: 0.8123\n",
            "Epoch 36/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.7691 - accuracy: 0.8219 - val_loss: 0.8885 - val_accuracy: 0.7922\n",
            "Epoch 37/200\n",
            "390/390 [==============================] - 28s 71ms/step - loss: 0.7589 - accuracy: 0.8281 - val_loss: 0.8428 - val_accuracy: 0.8065\n",
            "Epoch 38/200\n",
            "390/390 [==============================] - 28s 71ms/step - loss: 0.7431 - accuracy: 0.8335 - val_loss: 0.8389 - val_accuracy: 0.8081\n",
            "Epoch 39/200\n",
            "390/390 [==============================] - 28s 71ms/step - loss: 0.7481 - accuracy: 0.8319 - val_loss: 0.8593 - val_accuracy: 0.8025\n",
            "Epoch 40/200\n",
            "390/390 [==============================] - 28s 71ms/step - loss: 0.7399 - accuracy: 0.8324 - val_loss: 0.8236 - val_accuracy: 0.8123\n",
            "Epoch 41/200\n",
            "390/390 [==============================] - 28s 71ms/step - loss: 0.7250 - accuracy: 0.8398 - val_loss: 0.8062 - val_accuracy: 0.8177\n",
            "Epoch 42/200\n",
            "390/390 [==============================] - 28s 71ms/step - loss: 0.7273 - accuracy: 0.8391 - val_loss: 0.8622 - val_accuracy: 0.8006\n",
            "Epoch 43/200\n",
            "390/390 [==============================] - 28s 71ms/step - loss: 0.7256 - accuracy: 0.8387 - val_loss: 0.8441 - val_accuracy: 0.8121\n",
            "Epoch 44/200\n",
            "390/390 [==============================] - 28s 71ms/step - loss: 0.7147 - accuracy: 0.8434 - val_loss: 0.7668 - val_accuracy: 0.8261\n",
            "Epoch 45/200\n",
            "390/390 [==============================] - 28s 71ms/step - loss: 0.7159 - accuracy: 0.8444 - val_loss: 0.7335 - val_accuracy: 0.8396\n",
            "Epoch 46/200\n",
            "390/390 [==============================] - 27s 70ms/step - loss: 0.7151 - accuracy: 0.8437 - val_loss: 0.8815 - val_accuracy: 0.7958\n",
            "Epoch 47/200\n",
            "390/390 [==============================] - 28s 71ms/step - loss: 0.7049 - accuracy: 0.8465 - val_loss: 0.8028 - val_accuracy: 0.8188\n",
            "Epoch 48/200\n",
            "390/390 [==============================] - 28s 71ms/step - loss: 0.6966 - accuracy: 0.8493 - val_loss: 0.7747 - val_accuracy: 0.8300\n",
            "Epoch 49/200\n",
            "390/390 [==============================] - 28s 71ms/step - loss: 0.6962 - accuracy: 0.8499 - val_loss: 0.8077 - val_accuracy: 0.8189\n",
            "Epoch 50/200\n",
            "390/390 [==============================] - 28s 71ms/step - loss: 0.7031 - accuracy: 0.8491 - val_loss: 0.7547 - val_accuracy: 0.8415\n",
            "Epoch 51/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.6917 - accuracy: 0.8540 - val_loss: 0.7673 - val_accuracy: 0.8295\n",
            "Epoch 52/200\n",
            "390/390 [==============================] - 28s 71ms/step - loss: 0.6857 - accuracy: 0.8538 - val_loss: 0.8516 - val_accuracy: 0.8148\n",
            "Epoch 53/200\n",
            "390/390 [==============================] - 28s 71ms/step - loss: 0.6812 - accuracy: 0.8581 - val_loss: 0.7789 - val_accuracy: 0.8335\n",
            "Epoch 54/200\n",
            "390/390 [==============================] - 28s 71ms/step - loss: 0.6773 - accuracy: 0.8574 - val_loss: 0.8669 - val_accuracy: 0.8027\n",
            "Epoch 55/200\n",
            "390/390 [==============================] - 28s 71ms/step - loss: 0.6781 - accuracy: 0.8578 - val_loss: 0.7881 - val_accuracy: 0.8284\n",
            "Epoch 56/200\n",
            "390/390 [==============================] - 28s 71ms/step - loss: 0.6701 - accuracy: 0.8614 - val_loss: 0.7495 - val_accuracy: 0.8379\n",
            "Epoch 57/200\n",
            "390/390 [==============================] - 28s 71ms/step - loss: 0.6706 - accuracy: 0.8609 - val_loss: 0.7669 - val_accuracy: 0.8311\n",
            "Epoch 58/200\n",
            "390/390 [==============================] - 28s 71ms/step - loss: 0.6657 - accuracy: 0.8612 - val_loss: 0.7565 - val_accuracy: 0.8415\n",
            "Epoch 59/200\n",
            "390/390 [==============================] - 28s 71ms/step - loss: 0.6611 - accuracy: 0.8641 - val_loss: 0.7416 - val_accuracy: 0.8432\n",
            "Epoch 60/200\n",
            "390/390 [==============================] - 28s 71ms/step - loss: 0.6655 - accuracy: 0.8611 - val_loss: 0.7889 - val_accuracy: 0.8238\n",
            "Epoch 61/200\n",
            "390/390 [==============================] - 28s 71ms/step - loss: 0.6578 - accuracy: 0.8641 - val_loss: 0.8054 - val_accuracy: 0.8265\n",
            "Epoch 62/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.6518 - accuracy: 0.8688 - val_loss: 0.7611 - val_accuracy: 0.8392\n",
            "Epoch 63/200\n",
            "390/390 [==============================] - 28s 71ms/step - loss: 0.6606 - accuracy: 0.8643 - val_loss: 0.8136 - val_accuracy: 0.8287\n",
            "Epoch 64/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.6468 - accuracy: 0.8709 - val_loss: 0.7646 - val_accuracy: 0.8385\n",
            "Epoch 65/200\n",
            "390/390 [==============================] - 28s 71ms/step - loss: 0.6372 - accuracy: 0.8741 - val_loss: 0.8153 - val_accuracy: 0.8267\n",
            "Epoch 66/200\n",
            "390/390 [==============================] - 28s 71ms/step - loss: 0.6460 - accuracy: 0.8703 - val_loss: 0.7476 - val_accuracy: 0.8456\n",
            "Epoch 67/200\n",
            "390/390 [==============================] - 28s 71ms/step - loss: 0.6516 - accuracy: 0.8687 - val_loss: 0.7886 - val_accuracy: 0.8318\n",
            "Epoch 68/200\n",
            "390/390 [==============================] - 28s 71ms/step - loss: 0.6461 - accuracy: 0.8688 - val_loss: 0.6909 - val_accuracy: 0.8626\n",
            "Epoch 69/200\n",
            "390/390 [==============================] - 28s 71ms/step - loss: 0.6439 - accuracy: 0.8691 - val_loss: 0.7157 - val_accuracy: 0.8581\n",
            "Epoch 70/200\n",
            "390/390 [==============================] - 28s 71ms/step - loss: 0.6431 - accuracy: 0.8712 - val_loss: 0.7295 - val_accuracy: 0.8470\n",
            "Epoch 71/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.6311 - accuracy: 0.8772 - val_loss: 0.7522 - val_accuracy: 0.8396\n",
            "Epoch 72/200\n",
            "390/390 [==============================] - 28s 71ms/step - loss: 0.6274 - accuracy: 0.8783 - val_loss: 0.7708 - val_accuracy: 0.8440\n",
            "Epoch 73/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.6322 - accuracy: 0.8754 - val_loss: 0.7443 - val_accuracy: 0.8458\n",
            "Epoch 74/200\n",
            "390/390 [==============================] - 28s 71ms/step - loss: 0.6218 - accuracy: 0.8792 - val_loss: 0.7009 - val_accuracy: 0.8590\n",
            "Epoch 75/200\n",
            "390/390 [==============================] - 28s 71ms/step - loss: 0.6210 - accuracy: 0.8792 - val_loss: 0.7753 - val_accuracy: 0.8387\n",
            "Epoch 76/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.6202 - accuracy: 0.8782 - val_loss: 0.7005 - val_accuracy: 0.8612\n",
            "Epoch 77/200\n",
            "390/390 [==============================] - 28s 71ms/step - loss: 0.6182 - accuracy: 0.8800 - val_loss: 0.7526 - val_accuracy: 0.8456\n",
            "Epoch 78/200\n",
            "390/390 [==============================] - 28s 71ms/step - loss: 0.6249 - accuracy: 0.8784 - val_loss: 0.7077 - val_accuracy: 0.8599\n",
            "Epoch 79/200\n",
            "390/390 [==============================] - 28s 71ms/step - loss: 0.6145 - accuracy: 0.8849 - val_loss: 0.7307 - val_accuracy: 0.8461\n",
            "Epoch 80/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.6246 - accuracy: 0.8798 - val_loss: 0.7335 - val_accuracy: 0.8456\n",
            "Epoch 81/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.6085 - accuracy: 0.8829 - val_loss: 0.7697 - val_accuracy: 0.8404\n",
            "Epoch 82/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.6112 - accuracy: 0.8828 - val_loss: 0.7648 - val_accuracy: 0.8421\n",
            "Epoch 83/200\n",
            "390/390 [==============================] - 28s 71ms/step - loss: 0.6079 - accuracy: 0.8848 - val_loss: 0.7146 - val_accuracy: 0.8565\n",
            "Epoch 84/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.6065 - accuracy: 0.8834 - val_loss: 0.7068 - val_accuracy: 0.8592\n",
            "Epoch 85/200\n",
            "390/390 [==============================] - 28s 71ms/step - loss: 0.6074 - accuracy: 0.8865 - val_loss: 0.7521 - val_accuracy: 0.8419\n",
            "Epoch 86/200\n",
            "390/390 [==============================] - 28s 71ms/step - loss: 0.6043 - accuracy: 0.8864 - val_loss: 0.7389 - val_accuracy: 0.8496\n",
            "Epoch 87/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.6012 - accuracy: 0.8860 - val_loss: 0.7304 - val_accuracy: 0.8523\n",
            "Epoch 88/200\n",
            "390/390 [==============================] - 28s 71ms/step - loss: 0.5963 - accuracy: 0.8901 - val_loss: 0.7130 - val_accuracy: 0.8594\n",
            "Epoch 89/200\n",
            "390/390 [==============================] - 28s 71ms/step - loss: 0.6013 - accuracy: 0.8853 - val_loss: 0.7399 - val_accuracy: 0.8531\n",
            "Epoch 90/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5949 - accuracy: 0.8895 - val_loss: 0.7356 - val_accuracy: 0.8509\n",
            "Epoch 91/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.6008 - accuracy: 0.8856 - val_loss: 0.7912 - val_accuracy: 0.8354\n",
            "Epoch 92/200\n",
            "390/390 [==============================] - 28s 71ms/step - loss: 0.5913 - accuracy: 0.8892 - val_loss: 0.7003 - val_accuracy: 0.8599\n",
            "Epoch 93/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5893 - accuracy: 0.8921 - val_loss: 0.7175 - val_accuracy: 0.8601\n",
            "Epoch 94/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5958 - accuracy: 0.8897 - val_loss: 0.7190 - val_accuracy: 0.8540\n",
            "Epoch 95/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5974 - accuracy: 0.8889 - val_loss: 0.7149 - val_accuracy: 0.8547\n",
            "Epoch 96/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5972 - accuracy: 0.8884 - val_loss: 0.7137 - val_accuracy: 0.8555\n",
            "Epoch 97/200\n",
            "390/390 [==============================] - 28s 71ms/step - loss: 0.5890 - accuracy: 0.8899 - val_loss: 0.7452 - val_accuracy: 0.8487\n",
            "Epoch 98/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5874 - accuracy: 0.8927 - val_loss: 0.6980 - val_accuracy: 0.8642\n",
            "Epoch 99/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5827 - accuracy: 0.8917 - val_loss: 0.6888 - val_accuracy: 0.8675\n",
            "Epoch 100/200\n",
            "390/390 [==============================] - 28s 71ms/step - loss: 0.5835 - accuracy: 0.8918 - val_loss: 0.7274 - val_accuracy: 0.8557\n",
            "Epoch 101/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5794 - accuracy: 0.8943 - val_loss: 0.7231 - val_accuracy: 0.8575\n",
            "Epoch 102/200\n",
            "390/390 [==============================] - 28s 71ms/step - loss: 0.5854 - accuracy: 0.8924 - val_loss: 0.7283 - val_accuracy: 0.8538\n",
            "Epoch 103/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5814 - accuracy: 0.8943 - val_loss: 0.7152 - val_accuracy: 0.8575\n",
            "Epoch 104/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5768 - accuracy: 0.8958 - val_loss: 0.7364 - val_accuracy: 0.8565\n",
            "Epoch 105/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5790 - accuracy: 0.8956 - val_loss: 0.7424 - val_accuracy: 0.8508\n",
            "Epoch 106/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5744 - accuracy: 0.8951 - val_loss: 0.7648 - val_accuracy: 0.8481\n",
            "Epoch 107/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5690 - accuracy: 0.8987 - val_loss: 0.7354 - val_accuracy: 0.8507\n",
            "Epoch 108/200\n",
            "390/390 [==============================] - 28s 71ms/step - loss: 0.5688 - accuracy: 0.8998 - val_loss: 0.7236 - val_accuracy: 0.8580\n",
            "Epoch 109/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5665 - accuracy: 0.8996 - val_loss: 0.7113 - val_accuracy: 0.8592\n",
            "Epoch 110/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5628 - accuracy: 0.9000 - val_loss: 0.7119 - val_accuracy: 0.8588\n",
            "Epoch 111/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5674 - accuracy: 0.8995 - val_loss: 0.7386 - val_accuracy: 0.8522\n",
            "Epoch 112/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5654 - accuracy: 0.8991 - val_loss: 0.7134 - val_accuracy: 0.8613\n",
            "Epoch 113/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5699 - accuracy: 0.8987 - val_loss: 0.7043 - val_accuracy: 0.8674\n",
            "Epoch 114/200\n",
            "390/390 [==============================] - 28s 71ms/step - loss: 0.5673 - accuracy: 0.8989 - val_loss: 0.7276 - val_accuracy: 0.8529\n",
            "Epoch 115/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5625 - accuracy: 0.9012 - val_loss: 0.7770 - val_accuracy: 0.8425\n",
            "Epoch 116/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5669 - accuracy: 0.8989 - val_loss: 0.7346 - val_accuracy: 0.8569\n",
            "Epoch 117/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5606 - accuracy: 0.9011 - val_loss: 0.6984 - val_accuracy: 0.8643\n",
            "Epoch 118/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5603 - accuracy: 0.9014 - val_loss: 0.7028 - val_accuracy: 0.8630\n",
            "Epoch 119/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5581 - accuracy: 0.9016 - val_loss: 0.7516 - val_accuracy: 0.8506\n",
            "Epoch 120/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5597 - accuracy: 0.9001 - val_loss: 0.7377 - val_accuracy: 0.8553\n",
            "Epoch 121/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5473 - accuracy: 0.9055 - val_loss: 0.6780 - val_accuracy: 0.8701\n",
            "Epoch 122/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5535 - accuracy: 0.9026 - val_loss: 0.7184 - val_accuracy: 0.8602\n",
            "Epoch 123/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5514 - accuracy: 0.9051 - val_loss: 0.6994 - val_accuracy: 0.8653\n",
            "Epoch 124/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5600 - accuracy: 0.9005 - val_loss: 0.7739 - val_accuracy: 0.8459\n",
            "Epoch 125/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5459 - accuracy: 0.9067 - val_loss: 0.6955 - val_accuracy: 0.8626\n",
            "Epoch 126/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5499 - accuracy: 0.9065 - val_loss: 0.7887 - val_accuracy: 0.8400\n",
            "Epoch 127/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5487 - accuracy: 0.9046 - val_loss: 0.6931 - val_accuracy: 0.8684\n",
            "Epoch 128/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5532 - accuracy: 0.9034 - val_loss: 0.7435 - val_accuracy: 0.8523\n",
            "Epoch 129/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5436 - accuracy: 0.9076 - val_loss: 0.6740 - val_accuracy: 0.8692\n",
            "Epoch 130/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5489 - accuracy: 0.9051 - val_loss: 0.7605 - val_accuracy: 0.8476\n",
            "Epoch 131/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5465 - accuracy: 0.9055 - val_loss: 0.7496 - val_accuracy: 0.8515\n",
            "Epoch 132/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5415 - accuracy: 0.9065 - val_loss: 0.7716 - val_accuracy: 0.8469\n",
            "Epoch 133/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5468 - accuracy: 0.9058 - val_loss: 0.7053 - val_accuracy: 0.8609\n",
            "Epoch 134/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5459 - accuracy: 0.9049 - val_loss: 0.6944 - val_accuracy: 0.8663\n",
            "Epoch 135/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5375 - accuracy: 0.9094 - val_loss: 0.7565 - val_accuracy: 0.8520\n",
            "Epoch 136/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5376 - accuracy: 0.9101 - val_loss: 0.7191 - val_accuracy: 0.8647\n",
            "Epoch 137/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5420 - accuracy: 0.9086 - val_loss: 0.7100 - val_accuracy: 0.8614\n",
            "Epoch 138/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5364 - accuracy: 0.9114 - val_loss: 0.6873 - val_accuracy: 0.8678\n",
            "Epoch 139/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5374 - accuracy: 0.9083 - val_loss: 0.7560 - val_accuracy: 0.8541\n",
            "Epoch 140/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5455 - accuracy: 0.9054 - val_loss: 0.7348 - val_accuracy: 0.8607\n",
            "Epoch 141/200\n",
            "390/390 [==============================] - 28s 73ms/step - loss: 0.5320 - accuracy: 0.9102 - val_loss: 0.6768 - val_accuracy: 0.8705\n",
            "Epoch 142/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5357 - accuracy: 0.9092 - val_loss: 0.6844 - val_accuracy: 0.8691\n",
            "Epoch 143/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5309 - accuracy: 0.9116 - val_loss: 0.6986 - val_accuracy: 0.8647\n",
            "Epoch 144/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5406 - accuracy: 0.9068 - val_loss: 0.6966 - val_accuracy: 0.8654\n",
            "Epoch 145/200\n",
            "390/390 [==============================] - 28s 73ms/step - loss: 0.5350 - accuracy: 0.9104 - val_loss: 0.6960 - val_accuracy: 0.8661\n",
            "Epoch 146/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5303 - accuracy: 0.9123 - val_loss: 0.7550 - val_accuracy: 0.8552\n",
            "Epoch 147/200\n",
            "390/390 [==============================] - 28s 73ms/step - loss: 0.5324 - accuracy: 0.9121 - val_loss: 0.7275 - val_accuracy: 0.8603\n",
            "Epoch 148/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5290 - accuracy: 0.9125 - val_loss: 0.7499 - val_accuracy: 0.8529\n",
            "Epoch 149/200\n",
            "390/390 [==============================] - 28s 73ms/step - loss: 0.5340 - accuracy: 0.9085 - val_loss: 0.6981 - val_accuracy: 0.8736\n",
            "Epoch 150/200\n",
            "390/390 [==============================] - 28s 73ms/step - loss: 0.5279 - accuracy: 0.9146 - val_loss: 0.6666 - val_accuracy: 0.8783\n",
            "Epoch 151/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5266 - accuracy: 0.9137 - val_loss: 0.7299 - val_accuracy: 0.8594\n",
            "Epoch 152/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5312 - accuracy: 0.9129 - val_loss: 0.7567 - val_accuracy: 0.8514\n",
            "Epoch 153/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5240 - accuracy: 0.9142 - val_loss: 0.7219 - val_accuracy: 0.8650\n",
            "Epoch 154/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5190 - accuracy: 0.9146 - val_loss: 0.6885 - val_accuracy: 0.8692\n",
            "Epoch 155/200\n",
            "390/390 [==============================] - 28s 73ms/step - loss: 0.5296 - accuracy: 0.9110 - val_loss: 0.7342 - val_accuracy: 0.8563\n",
            "Epoch 156/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5199 - accuracy: 0.9132 - val_loss: 0.7268 - val_accuracy: 0.8593\n",
            "Epoch 157/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5206 - accuracy: 0.9131 - val_loss: 0.7294 - val_accuracy: 0.8649\n",
            "Epoch 158/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5236 - accuracy: 0.9154 - val_loss: 0.6844 - val_accuracy: 0.8666\n",
            "Epoch 159/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5252 - accuracy: 0.9105 - val_loss: 0.7233 - val_accuracy: 0.8606\n",
            "Epoch 160/200\n",
            "390/390 [==============================] - 28s 73ms/step - loss: 0.5204 - accuracy: 0.9141 - val_loss: 0.7073 - val_accuracy: 0.8657\n",
            "Epoch 161/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5209 - accuracy: 0.9160 - val_loss: 0.7855 - val_accuracy: 0.8442\n",
            "Epoch 162/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5209 - accuracy: 0.9131 - val_loss: 0.7136 - val_accuracy: 0.8633\n",
            "Epoch 163/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5323 - accuracy: 0.9102 - val_loss: 0.7387 - val_accuracy: 0.8566\n",
            "Epoch 164/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5227 - accuracy: 0.9126 - val_loss: 0.7209 - val_accuracy: 0.8591\n",
            "Epoch 165/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5186 - accuracy: 0.9143 - val_loss: 0.6697 - val_accuracy: 0.8735\n",
            "Epoch 166/200\n",
            "390/390 [==============================] - 28s 73ms/step - loss: 0.5155 - accuracy: 0.9169 - val_loss: 0.7515 - val_accuracy: 0.8552\n",
            "Epoch 167/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5098 - accuracy: 0.9180 - val_loss: 0.7837 - val_accuracy: 0.8487\n",
            "Epoch 168/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5177 - accuracy: 0.9142 - val_loss: 0.6780 - val_accuracy: 0.8715\n",
            "Epoch 169/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5172 - accuracy: 0.9155 - val_loss: 0.7385 - val_accuracy: 0.8545\n",
            "Epoch 170/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5112 - accuracy: 0.9194 - val_loss: 0.7969 - val_accuracy: 0.8462\n",
            "Epoch 171/200\n",
            "390/390 [==============================] - 28s 73ms/step - loss: 0.5126 - accuracy: 0.9169 - val_loss: 0.7122 - val_accuracy: 0.8651\n",
            "Epoch 172/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5161 - accuracy: 0.9143 - val_loss: 0.7565 - val_accuracy: 0.8552\n",
            "Epoch 173/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5125 - accuracy: 0.9165 - val_loss: 0.7090 - val_accuracy: 0.8643\n",
            "Epoch 174/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5132 - accuracy: 0.9172 - val_loss: 0.7344 - val_accuracy: 0.8591\n",
            "Epoch 175/200\n",
            "390/390 [==============================] - 28s 73ms/step - loss: 0.5095 - accuracy: 0.9185 - val_loss: 0.7193 - val_accuracy: 0.8661\n",
            "Epoch 176/200\n",
            "390/390 [==============================] - 28s 73ms/step - loss: 0.5083 - accuracy: 0.9187 - val_loss: 0.7372 - val_accuracy: 0.8628\n",
            "Epoch 177/200\n",
            "390/390 [==============================] - 28s 73ms/step - loss: 0.5198 - accuracy: 0.9143 - val_loss: 0.7055 - val_accuracy: 0.8669\n",
            "Epoch 178/200\n",
            "390/390 [==============================] - 28s 73ms/step - loss: 0.5021 - accuracy: 0.9191 - val_loss: 0.7094 - val_accuracy: 0.8693\n",
            "Epoch 179/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5133 - accuracy: 0.9174 - val_loss: 0.6834 - val_accuracy: 0.8735\n",
            "Epoch 180/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5063 - accuracy: 0.9203 - val_loss: 0.6740 - val_accuracy: 0.8753\n",
            "Epoch 181/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5077 - accuracy: 0.9180 - val_loss: 0.7221 - val_accuracy: 0.8643\n",
            "Epoch 182/200\n",
            "390/390 [==============================] - 29s 73ms/step - loss: 0.5091 - accuracy: 0.9166 - val_loss: 0.7018 - val_accuracy: 0.8698\n",
            "Epoch 183/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5141 - accuracy: 0.9165 - val_loss: 0.6821 - val_accuracy: 0.8725\n",
            "Epoch 184/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5087 - accuracy: 0.9172 - val_loss: 0.6942 - val_accuracy: 0.8694\n",
            "Epoch 185/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5053 - accuracy: 0.9201 - val_loss: 0.7102 - val_accuracy: 0.8683\n",
            "Epoch 186/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.4989 - accuracy: 0.9218 - val_loss: 0.7112 - val_accuracy: 0.8660\n",
            "Epoch 187/200\n",
            "390/390 [==============================] - 28s 73ms/step - loss: 0.5019 - accuracy: 0.9205 - val_loss: 0.7522 - val_accuracy: 0.8589\n",
            "Epoch 188/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.4986 - accuracy: 0.9205 - val_loss: 0.6779 - val_accuracy: 0.8764\n",
            "Epoch 189/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5087 - accuracy: 0.9202 - val_loss: 0.7214 - val_accuracy: 0.8595\n",
            "Epoch 190/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.4912 - accuracy: 0.9233 - val_loss: 0.7374 - val_accuracy: 0.8584\n",
            "Epoch 191/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5002 - accuracy: 0.9215 - val_loss: 0.7113 - val_accuracy: 0.8687\n",
            "Epoch 192/200\n",
            "390/390 [==============================] - 29s 73ms/step - loss: 0.5033 - accuracy: 0.9204 - val_loss: 0.7304 - val_accuracy: 0.8629\n",
            "Epoch 193/200\n",
            "390/390 [==============================] - 29s 73ms/step - loss: 0.5031 - accuracy: 0.9212 - val_loss: 0.7460 - val_accuracy: 0.8554\n",
            "Epoch 194/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.4992 - accuracy: 0.9220 - val_loss: 0.7177 - val_accuracy: 0.8662\n",
            "Epoch 195/200\n",
            "390/390 [==============================] - 28s 73ms/step - loss: 0.5000 - accuracy: 0.9227 - val_loss: 0.6999 - val_accuracy: 0.8714\n",
            "Epoch 196/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.4925 - accuracy: 0.9232 - val_loss: 0.7581 - val_accuracy: 0.8594\n",
            "Epoch 197/200\n",
            "390/390 [==============================] - 28s 73ms/step - loss: 0.4979 - accuracy: 0.9212 - val_loss: 0.7061 - val_accuracy: 0.8693\n",
            "Epoch 198/200\n",
            "390/390 [==============================] - 28s 73ms/step - loss: 0.5000 - accuracy: 0.9198 - val_loss: 0.7246 - val_accuracy: 0.8632\n",
            "Epoch 199/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.4932 - accuracy: 0.9242 - val_loss: 0.7559 - val_accuracy: 0.8594\n",
            "Epoch 200/200\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.4867 - accuracy: 0.9250 - val_loss: 0.6847 - val_accuracy: 0.8742\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PM2Ya6OxZX3C"
      },
      "source": [
        "tensorboard --logdir=\"/logs/mymodel\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLd1g0k_9UyX"
      },
      "source": [
        "import pandas as pd\r\n",
        "def to_csv(history,name):\r\n",
        "  dicts={'loss':history.history['loss'],'accuracy':history.history['accuracy'],'validation loss':history.history['val_loss']\r\n",
        "        , 'validation accuracy':history.history['val_accuracy']}\r\n",
        "\r\n",
        "  df= pd.DataFrame(dicts)\r\n",
        "\r\n",
        "  df.to_csv(name+\".csv\")\r\n",
        "  return\r\n",
        "\r\n",
        "to_csv(history,\"my_model\")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhO4gTKUSQ76"
      },
      "source": [
        "!mkdir -p saved_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Z5kDXBZSaPB",
        "outputId": "01edbdfd-c8f9-4597-c963-7ef22a2001d0"
      },
      "source": [
        "model.save('drive/MyDrive/saved_model/my_model')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: drive/MyDrive/saved_model/my_model/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83PDXLynRxob",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "666bdff2-e1c8-4288-b7f1-ec030a5ae291"
      },
      "source": [
        "print(\"The time to train the model:\",end-start)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The time to train the model: 5704.889621734619\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6hGHijfSkGq"
      },
      "source": [
        "import requests\r\n",
        "from PIL import Image\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTTx_9kgT5bV",
        "outputId": "aaf3913d-f477-4524-fc4f-4801135a2a2e"
      },
      "source": [
        "url =\"https://ichef.bbci.co.uk/news/976/cpsprodpb/12A9B/production/_111434467_gettyimages-1143489763.jpg\"\r\n",
        "response = requests.get(url,stream=True)\r\n",
        "print(response.status_code)\r\n",
        "img = Image.open(response.raw)\r\n",
        "img =tf.keras.preprocessing.image.img_to_array(img)\r\n",
        "img = tf.image.resize(img,[32,32])\r\n",
        "# img= tf.keras.preprocessing.image.array_to_img(img)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hh2qaArweqJX"
      },
      "source": [
        "def standardize(images,mean,std):\r\n",
        "  images = (images - mean)/(std+1e-7)\r\n",
        "  return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyhHCSWcq4y7"
      },
      "source": [
        "def show_image(images,labels,mean,std):\r\n",
        "  \r\n",
        "  fig = plt.figure(figsize=(25,10))\r\n",
        "\r\n",
        "  for i in np.arange(20):\r\n",
        "  \r\n",
        "    ax = fig.add_subplot(2,10,i+1)\r\n",
        "    plt.imshow(images[i])\r\n",
        "    plt.subplots_adjust(bottom=0.2,hspace=0.3,wspace=0.1)\r\n",
        "    my_image = tf.expand_dims(standardize(images[i],mean,std),axis=0)\r\n",
        "    pred = label[np.argmax(model.predict(my_image))]\r\n",
        "    l = label[np.argmax(labels[i])]\r\n",
        "   \r\n",
        "    ax.set_title('{} pred [{}]'.format(l,pred),color=(\"green\" if pred==l else \"red\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6Y7ozyzhcUN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}